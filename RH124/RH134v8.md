# RH134 - Red Hat System Administration II
Several of the labs can be run from a local install of RHEL or CentOS.  This not only 
saves online lab time but allows greater flexibility in experimenting and getting
hands-on experience.

These instructions assume you have a base RHEL or CentOS system installed.  I
recommend using [VirtualBox](https://www.virtualbox.org/) to install 
an OS which can be saved or deleted as needed.

Be sure to create a shared folder with your VM so you can copy files between the
host and the VM.

Chapters:  
[Chapter 1. Improving Command-line Productivity](#chapter-1---improving-command-line-productivity)  
[Chapter 2.  Scheduling Future Tasks](#chapter-2---scheduling-future-tasks)  
[Chapter 3. Tuning System Performance](#chapter-3---tuning-system-performance)  
[Chapter 4. Controlling Access to Files with ACLs](#chapter-4---controlling-access-to-files-with-acls)  
[Chapter 5. Managing SELinux Security](#chapter-5---managing-selinux-security)  
[Chapter 6. Managing Basic Storage](#chapter-6---managing-basic-storage)  
[Chapter 7. Managing Logical Volumes](#chapter-7---managing-logical-volumes)  
[Chapter 8. Implementing Advanced Storage Features](#chapter-8---implementing-advanced-storage-features)  
[Chapter 9. Accessing Network-Attached Storage](#chapter-9---accessing-network-attached-storage)  
[Chapter 10. Controlling the Boot Process](#chapter-10---controlling-the-boot-process)  
[Chapter 11. Managing Network Security](#chapter-11---managing-network-security)  
[Chapter 12. Installing Red Hat Enterprise Linux](#chapter-12---installing-red-hat-enterprise-linux)  
[Chapter 13. Comprehensive Review]()

## Chapter 1 - Improving Command-line Productivity
Bash shell scripts are files with sequences of commands.  First line should be:

```
#!/bin/bash
```

* 'Escaping' characters suppresses their special meaning.  Ie, `\#`, `\"`, etc
* Single quotes (`'xxx'`) preserve literal meaning of characters
* Double quotes (`"xxx"`) suppress globbing and shell expansion, allow command and variable substitution
* `echo text` - displays output
* `exit #` - exits script with exit code.  Use `$?` to access exit code
* Operators may be used to check for conditions.  See `man test` for list
* [ <expression> ] - test command, ie: `[1 -eq 1]; echo $?`
* [[ <expression> ]] - extended test, adds glob pattern and regex pattern matching
* Regular expressions: `man 7 regex`

For loop:

```
for <variable> in <list>; do
   <commands>
done
```

Examples:

```
for NUM in num1 num2 num3; do echo $NUM; done
for NUM in num{1..3}; do echo $NUM; done
for NUM in $(seq 2 2 10); do echo "$NUM"; done
```

If/then:

```
if <condition>; then
   <commands>
elif <condition>; then
   <commands>
else 
   <commands>   
fi
```

Regular expressions:

* `^` and `$` - anchors beginning and end of line
* `.` - wildcard matches any character
* `[xyz]` - matches x, y, or z
* `*` - matches zero or more of the previous expression
* `\{x\}` - matches previous expression x number of times
* Usually enclose in single quotes so shell doesn't interpret metacharacters
* `grep`, `sed`, `awk`, `vim`, `less`, etc - can use regex

Commands to know:
* `which <file>` - shows path and file which will be executed
* `grep` - searches for text pattern (regex).  `-i` - ignore case.  `-v` - lines not matching

### Labs
Labs can be run as documented.  
The section 4 lab has you ssh to different hosts.  To run the command as-is you may need a second VM.  
The section 6 lab assumes the `postfix` package was installed today.  To install the package: `yum -y install postfix`.  Start the postfix service: `systemctl start postfix`.

## Chapter 2 - Scheduling Future Tasks

Commands to know:

* `at <time>` - schedule command to run at certain time.  Takes input from STDIN, Ctrl+D to end.  Time may be given in several formats: `now +5min`, `noon +4 days`, `5pm august 3 2020`.  See `/usr/share/doc/at/timespec`
* `at -q <letter> <time>` - runs the job with priority `<letter>`.  a - highest, z - lowest
* `atq` - shows queued jobs
* `at -c #` - shows commands being executed for job #
* `atrm #` - removes job # from queue

* `crontab` - manages recurring jobs for user. `-r` - removes jobs.  `-l` - list jobs. `-e` - edit jobs
* crontab fields appear in the following order: `Minutes Hours Day_of_Month Month Day_of_Week Command`.  Syntax rules:
   * `*` - run always
   * For weekdays, 0 - Sunday, 1 - Monday . . .
   * `x-y` - sets range, inclusive
   * `x,y` - for lists.  Lists can include ranges
   * `*/x` - interval of `x`
   * Three-letter abbreviations for month and weekeday. `Mon`.  `Jan`

System-wide crontab defined in either `/etc/crontab` or files placed in `/etc/cron.d` directory.  Similar format to above except a user name is placed before the command.  
Scripts (not `crontab` files) may also be placed in the `/etc/cron.hourly`, `/etc/cron.daily`, `/etc/cron.weekly`, and `/etc/cron.monthly` directories.  These are run using the `/etc/cron.d/0hourly` (for hourly) and `/etc/anacrontab` (for all others).

Scheduling may also use `systemd` timer units.  Timer units may activate another unit time (like a service) when the unit name matches the timer unit name.  Modifications to the default profiles in `/usr/lib/systemd/system` should be placed in the `/etc/systemd/system` directory.  After a change run: `systemctl daemon-reload`, then `systemctl enable --now <unitname.timer>`.

Temporary files:

Creation and cleanup handled by `systemd-tmpfiles-clean.timer`.  View config file with: `systemctl cat systemd-tmpfiles-clean.timer`.

Manual cleanup is done using `systemd-tmpfiles --clean`.  See `man 5 tmpfiles.d` for details on the config file format.  Configuration files are:

* `/etc/tmpfiles.d/*.conf` - custom files go here
* `/run/tmpfiles.d/*.conf` - volitile
* `/usr/lib/tmpfiles.d/*.conf` - provided by system, do not edit

### Labs
Labs can be run as documented.

## Chapter 3 - Tuning System Performance

Commands to know:

* `tuned-adm active` - display active profile
* `tuned-adm list` - list profiles
* `tuned-adm profile <profile>` - switch to new profile
* `tuned-adm recommend` - show recommended profile
* `tuned-adm off` - turns off tuning

_Nice_ levels range from -20 (highest priority) to 19 (lowest priority).

* `top` - Nice values shown in `NI` column.  Sheduled priority shown in `PR` column
* `ps axo pid,comm,nice,cls --sort=-nice`
* `ps -o pid,comm,nice <pid_num>` - shows nice level for specified PID

* `nice <command>` - by default starts process with nice level of 10
* `nice -n xx <command>` - starts process with nice level of `xx`
* `renice -n xx <pid_num>` - changes nice level of PID
* `top` - renice process using `r` option

### Labs
Labs can be run as documented.  
Before starting the chapter 3 section 5 lab, start two processes:

```
md5sum /dev/zero &
sha1sum /dev/zero &
```

## Chapter 4 - Controlling Access to Files with ACLs

Commands to know:

* `ls -l` - shows `+` at end of permission string if ACLs set
* `getfacl fn` - display ACLs on fn

ACL mask defines maximum permissions for named users, group owner, and named groups.  Does not apply to file owner or other users.

* `setfacl -m u:name:rX file` - Modifies ACL for user `name`.  If `name` is blank applies to owner
* `setfacl -m g:group:rw file` - Modifies ACL for group `group`.  If `group` is blank applies to group owner
* `setfacl -m o::- file` - Modifies ACL for other users.  In this case, no permissions
* `getfacl fn | setfacl --set-file=- fn2` - Sets ACL on `fn2` to be the same as `fn1`
* `setfacl -m m::r file` - Sets ACL mask
* `setfacl -R -m u:name:rX dir` - Recursivly set ACL on directories
* `setfacl -x u:name,g:name file` - Removes ACL for specified user/group
* `setfacl -b file` - Removes all ACLs for file
* `setfacl -m d:u:name:rx dir` - Sets the default ACLs on a directory - used for inheritance

### Labs
Labs can be run as documented.

#### Section 4 Lab
For section 4 lab, create the users and groups (switch to root first):

```
for USER in sysadmin1 operator1 consultant1 consultant2;do adduser $USER;done
for USER in sysadmin1 operator1 consultant1 consultant2;do passwd $USER;done
groupadd operators
groupadd consultants
usermod -aG operators sysadmin1
usermod -aG consultants consultant1
usermod -aG consultants consultant2
mkdir -p /shares/content/server-info
chgrp -R operators /shares
chmod -R g+s /shares
```

Set up the sample files used in the lab.  First, create a script file called `/shares/content/loadavg.sh` with the following:

```
#!/bin/bash
echo '#################################################'
hostname
echo '#################################################'
date
echo '#################################################'
cat /proc/loadavg
echo '#################################################'
```

Then run the following commands:

```
chmod +x /shares/content/loadavg.sh
/shares/content/loadavg.sh > /shares/content/serverb-loadavg.txt
```

#### Section 5 Lab
Create the users and groups necessary.  As root:

```
for USER in manager{1..2} contractor{1..3};do adduser $USER;done
for USER in manager{1..2} contractor{1..3};do passwd $USER;done
groupadd managers
groupadd contractors
for USER in contractor{1..3};do usermod -aG contractors $USER;done
for USER in manager{1..2};do usermod -aG managers $USER;done
mkdir -p /shares/cases
touch /shares/cases/shortlist.txt
touch /shares/cases/backlog.txt
```

## Chapter 5 - Managing SELinux Security
SELinux has three operating modes:

| Enforcing  | Enforces all rules
| Permissive | Doesn't enforce, but provides warnings
| Disabled   | Turned off

SELinux contexts have the following format:

```
system_u:object_r:httpd_sys_content_t:s0  /var/www/html
-------- -------- ------------------- --
 User      Role        Type           Level
```

Commands to know:

* `ls -Z` - Displays SELinux context
* `-Z` also works with `ps`, `cp`, `mkdir`, etc
* `ps axZ` - Displays context for processes

* `getenforce` - Displays current SELinux mode
* `setenforce [ Enforcing | Permissive | 1 | 0 ]` - Sets mode

See also the `/etc/selinux/config` file.

Changing contexts:

* `chcon -t <context_type> <fn>` - Changes context of `fn` to context type.  Not saved in SELinux context database
* `restorecon -v <fn>` - Restores context to default value
* `semanage fcontext` - Updates context databases.  `restorecon` uses this value when run.  `-a` adds, `-d` deletes, `-l` lists

* `semanage fcontext -l` - Lists all default rules 
* `restorecon -Rv <dir>` - Recursively restores contexts. `-F` forces reset

Install the SELinux policy documentation:

```
yum -y install selinux-policy-doc
man -k '_selinux'
```

SELinux booleans:

* `getsebool -a` - Lists current values
* `setsebool <boolean> <on|off>` - Sets a boolean value.  `-P` writes pending value to policy.  Needed for persistence
* `semanage boolean -l` - Lists booleans, state, default value, and description
* `semanage boolean -l -C` - Lists booleans where state and default are different

Troubleshooting:

* Audit log is `/var/log/audit/audit.log`
* Messages stored in `/var/log/messages`
* `sealert -l UUID` - Provides more readable info on error.  UUID is shown in `messages` file
* `ausearch -m AVC -ts recent` - Searches `audit.log` file.  `-m` is message type.  `-ts` searches based on time

### Labs
Labs can be run as documented.  Be sure to make a backup of `httpd.conf` before making changes.

If Apache isn't installed:

```
yum -y install httpd
```

By default port 80 for `http` access will not be open in the firewall.  To open the port:

```
firewall-cmd --add-service=http --permanent
firewall-cmd --reload
firewall-cmd --list-all
```

At the start of the section 8 lab, the `index.html` file may already have the appropriate permissions.  To reset:

```
echo 'This is a new index file.' > ~/index.html
rm /var/www/html/index.html
mv ~/index.html /var/www/html
```

Setup for the section 9 lab is similar to what was done earlier with the `/custom` directory, but this time create `/lab-content`.

## Chapter 6 - Managing Basic Storage
*Master Boot Record* - MBR - is the old way of partitioning.  Max of 4 primary partitions, and max of 15 total partitions using extended partitions.  Max disk/partition size is 2 TiB.  
*GUID Partition Table* - GPT - provides up to 128 partitions and supports disks/partitions up to 8 ZiB.  Also maintains backup partition table at end of disk.

`parted` manages both MBR and GPT schemes.  _*Changes are written immediately.  Use with caution!*_

* `parted /dev/sda print` - shows current partitions on device.  Partition Table of type `msdos` is MBR.
* `parted /dev/sda` - no parameters opens `parted` in interactive session
* `parted /dev/sda unit [s|B|MiB|GiB|TiB|MB|GB|TB] print` - shows size in sectors, bytes, etc
* `parted /dev/sda mklabel msdos` - labels disk as MBR.  Wipes current table!
* `parted /dev/sda mklabel gpt` - labels disk as GPT.  Wipes current table!
* `parted /dev/sda help mkpart` - lists supported file-system types

Create MBR partition:

1. `parted /dev/sda` - open interactive session for disk
1. `mkpart`, then `primary` or `extended` - to create primary or extended partition
1. `xfs`, or whichever file system to be used
1. Specify start and end.  By default `MB` is used,  use `s` for sector, etc.  Best to start with a sector which is a multiple of 2048.  Size can't be specified directly, but size = end - start
1. Partition will be created immediately after specifying end.  Use `quit` to exit
1. `udevadm settle` - waits for system to detect new partition and create device under `/dev`

May also be specified on a single line:

```
parted /dev/sda mkpart primary xfs 2048s 20GiB
```

Create GPT partition:

1. `parted /dev/sda` - open interactive session for disk
1. `mkpart`, then provide partition name
1. `xfs`, or whichever file system to be used
1. Specify start and end.  By default `MB` is used,  use `s` for sector, etc.  Best to start with a sector which is a multiple of 2048.  Size can't be specified directly, but size = end - start
1. Partition will be created immediately after specifying end.  Use `quit` to exit
1. `udevadm settle` - waits for system to detect new partition and create device under `/dev`

May also be specified on a single line:

```
parted /dev/sda mkpart mydata xfs 2048s 20GiB
```

Delete partition:

1. `parted /dev/sda` - open interactive session for disk
1. `print` - print partition table.  Each partition will have a partition number
1. `rm #` - removes partition `#`
1. `quit` - to exit interactive session

Create file system:

* `mkfs.xfs /dev/sda1` - to create file system on device.  Other file systems also supported in similar manner

Mount file system:

* `mount /dev/sda1 /mnt` - to mount the new drive onto directory `/mnt`  
* `mount` - with no parameters to see status of current mounts
* `/etc/fstab` - file used to automatically mount file systems
* `systemctl daemon-reload` - after making changes to `fstab`
* `lsblk --fs` - lists block devices, shows UUID and mount points

`fstab` format:

```
UUID=b2afe8f9-b17f-45fb-a47f-413944d034ce /boot   xfs    defaults  0 0
----------------------------------------- -----   ----   --------  - -
   UUID or device name                    mount   fstype  options  used by dump and fsck
                                          point
```

Swap space is stored in a special partition - `linux-swap`.  It should be sized appropriately, especially if the computer
uses hibernation since all memory is stored to disk.  

* Follow process above for creating a GPT partition, but make it type `linux-swap`.  
* `mkswap /dev/sdc1` - to format swap area
* `swapon /dev/sdc1` - to activate the swap area
* `free` - shows free memory and swap size
* `swapoff /dev/sdc1` - deactivates swap area
* `swapon --show` - Displays swap areas currently activated
* `swapon -a` - Enables all swap partitions defined in `fstab`

Use `fstab` to make persistent:

```
UUID=b107bba0-dfd1-4e92-97fe-e52fb2dc38d3 swap  swap    defaults        0 0
```

Priority may also be set in the `fstab` file.  Ie, `pri=4` where the options keywords are specified.  Default priority is -2.



### Labs
You will want to create some extra virtual drives in order to practice creating partitions and file systems.  This can usually easily been done using your VirtualBox or other virtualization software's interface.  With VirtualBox you can also create
one [from the command line](https://wspstech.blogspot.com/2020/01/create-virtualbox-hard-drive-from.html).

Use the `lsblk --fs` command to list devices.  Your new drive should not have a file system yet.  In this example there are
two new devices - `sdb` and `sdc`:

```
[ansible@ansible3 ~]$ lsblk --fs
NAME        FSTYPE      LABEL          UUID                                   MOUNTPOINT
sda                                                                           
├─sda1      ext4                       6dd3ee35-ab58-40a0-a3f7-3d3b0ac28ad3   /boot
└─sda2      LVM2_member                Ctid4m-z8tK-GRah-eGFo-2Dhk-jLrO-mZoniG 
  ├─cl-root xfs                        850f2d8b-067d-49fb-802b-433147738ce5   /
  └─cl-swap swap                       e7531c73-d072-41bc-b768-3a19d153cedc   [SWAP]
sdb                                                                           
sdc
```

`parted -l` will also show these devices having an "unrecognized disk label."

## Chapter 7 - Managing Logical Volumes
Terminology:
* *Physical device* - physical block devices such as disk drives
* *Physical Volume (PV)* - identify a device to be used in LVM
* *Volume Group (VG)* - Storage pool of one or more PVs
* *Logical Volume (LV)* - Created from VG to provide a storage device
* *Physical Extent (PE)* - Small chunks of data which act as storage block on PV
* *Logical Extent (LE)* - Maps to one or more PEs and make up LVs

Steps for creating LVM storage:

1. Identify physical device(s) which will be used
1. Initialize devices as PVs to be used with LVM
1. Combine one or more PVs into a VG
1. LVs created from VG free space
1. Format, mount LVs to be used

Detailed steps:

1. Used `parted` to create partitions as in previous chapter
1. `parted -s /dev/sdd set 1 lvm on` - Sets the LVM flag on for partition 1
1. `pvcreate /dev/sdd1 /dev/sdd2` - Labels device(s) as physical volumes
1. `vgcreate <vg_name> /dev/sdd1 /dev/sdd2` - Creates volume group and adds PVs
1. `lvcreate -n <lv_name> -L <size> <vg_name>` - Creates an LV
1. `mkfs.xfs /dev/<vg_name>/<lv_name>` - Format LV as xfs or whatever filesystem type you desire
1. Add to `fstab` as `/dev/...` rather than UUID

Other commands to know:

* `lvremove /dev/...` - Destroys LV.  Be sure LV is not mounted
* `vgremove <vg_name>` - Removes VG
* `pvremove /dev/sdd1 /dev/sdd2` - Removes PVs
* `pvdisplay /dev/sdd1` - Display info for PV
* `vgdisplay <vg_name>` - Display info for VG
* `lvdisplay /dev/<vg_name>/<lv_name>` - Display info for LV

* `vgextend <vg_name> /dev/..` - Extends volume group by adding additional devices (`pvcreate` must have been run on the device)
* `pvmove /dev/sdd3` - Relocates PEs from PV to other PVs in VG
* `vgreduce <vg_name> /dev/sdd3` - Removes PV from VG
* `lvextend -L +300M /dev/<vg_name>/<lv_name>` - Extends LV by 300MiB.  `-r` automatically resizes file system too
* `xfs_growfs /mnt/data` - Grows xfs file system to match new size of LV
* `resize2fs /dev/<vg_name>/<lv_name>` - Grows ext4 file system to match size of LV.  `-p` to monitor progress
* For swap, `swapoff` on device to deactivate, use `lvextend` to extend, `mkswap` to reformat, then `swapon` to enable

### Labs
Create a couple of empty virtual drives similar to what you did in the previous chapter.

## Chapter 8 - Implementing Advanced Storage Features

Stratis commands:

* `yum install stratis-cli stratisd` - Install Stratis
* `stratis pool create <pool_name> /dev/vdb` - Creates pool with one or more devices
* `stratis pool list` - Lists pools
* `stratis pool add-data <pool_name> /dev/vdc` - Adds device to pool
* `stratis blockdev list <pool_name>` - List block devices of pool
* `stratis filesystem create <pool_name> <fs_name>` - Create dynamic file system
* `stratis filesystem snapshot <pool_name> <fs_name> <snapshot_name>` - Create snapshot of filesystem
* `stratis filesystem list` - List available file systems
* `stratis filesystem destroy <pool_name> <fs_name>` - Destroy file system

`fstab` can be used to persistently mount Stratis file system:

```
UUID=31b9...8c55 /dir xfs defaults,x-systemd.requires=stratisd.service 0 0
```

VDO commands:

* `yum install vdo kmod-kvdo` - Install VDO
* `vdo create --name=<vdo_name> --device=/dev/vdd --vdoLogicalSize=50G` - Creates VDO volume using device
* `vdo status --name=<vdo_name>` - Displays report on VDO volume
* `vdo list` - List of VDO volumes which are started
* `vdo stop|start` - Stops or starts a VDO volume
* `mkfs.xfs -K /dev/mapper/<vdo_name>` - Format as xfs
* `vdostats --human-redable` - Shows statistics for VDO volumes

### Labs
Create a couple of empty virtual drives similar to what you did in chapter 6.  Be sure the drives have a minimum of 1GB for Stratis.  When running to create a storage pool you may either add unpartitioned drives such as `/dev/sdb` or a partition `/dev/sdb1`.

For Stratis create a drive which is at a minimum of 5GB.  For the lab in section 4 create a large file to copy:

```
dd if=/dev/urandom of=install.img bs=1M count=1024
```

## Chapter 9 - Accessing Network-Attached Storage

Commands to know for mounting:

* `mount -t nfs -o rw,sync <server>:/<share/mountpoint>` - mounts NFS share
* `fstab` has format: `<server>:/<share/mountpoint> nfs rw,soft 0 0`

NFS Configuration Tool:

* Configuration is in `/etc/nfs.conf`
* `nfsconf --set <section> <key> <value>` - to set a configuration option.  Ie: `nfsconf --set nfsd vers4.2 y`
* `nfsconf --get <section> <key>` - retrieves configuration option.  Ie: `nfsconf --get nfsd vers4.2`
* `nfsconf --unset <section> <key>` - unsets the option.  Ie: `nfsconf --unset nfsd vers4.2`

Create an NFS 4 client/server:

```
nfsconf --set nfsd udp n
nfsconf --set nfsd vers2 n
nfsconf --set nfsd vers3 n
nfsconf --set nfsd tcp y
nfsconf --set nfsd vers4 y
nfsconf --set nfsd vers4.0 y
nfsconf --set nfsd vers4.1 y
nfsconf --set nfsd vers4.2 y
```

Automounter:

* `yum install autofs` - Installs automounter
* Master map file placed in `/etc/auto.master.d` having the following format (usually with `.autofs` extension):
   ```
   /shares /etc/<mount_detail_file>
   ```
* `<mount_detail_file>` has the following format:
   ```
   <subdir> -rw,sync <server>:/<nfs_share>
   ```
   where `<subdir>` will be a subdirectory under the `/shares` directory specified in the master map file
* `systemctl enable --now autofs` - Starts and enables the service

For direct mounts, master map file will look like:

```
/- /etc/<mount_detail_file>
```

and the mount detail file will look like:

```
<mount_directory> -rw,sync <server>:/<nfs_share>
```

Indirect wildcard maps are used when NFS exports multiple subdirectories in a directory.  The mount detail file will look like:

```
* -rw,sync <server>:/<nfs_share>/&
```


### Labs
For this chapter you will need to set up an NFS server preferably on a different VM.  On your NFS server:

1. `dnf install nfs-utils` - Install the NFS server
1. `systemctl enable --now nfs-server` - Start the server automatically
1. Configure the firewall to allow NFS traffic:
   ```
   firewall-cmd --add-service=nfs --permanent
   firewall-cmd --reload
   ```
1. Follow the instructions for step 2 in the section 2 lab to set the server up for NFSv4 only.  Do these steps on your NFS server.

Create the users and groups on both the *NFS client* and on the *NFS server*.  Be sure the group GID and the user UIDs match on both systems.

```
# Section 2 Lab Users
groupadd -g 1400 admin
useradd -u 1401 admin1
usermod -aG admin admin1

# Section 4 Lab Users
groupadd -g 1500 operators
groupadd -g 1600 contractors
useradd -u 1501 operator1
useradd -u 1601 contractor1
usermod -aG operators operator1
usermod -aG contractors contractor1

# Section 5 Lab Users
groupadd -g 1700 managers
groupadd -g 1800 production
useradd -u 1701 manager1
useradd -u 1801 dbuser1
useradd -u 1503 consultant1
usermod -aG managers manager1
usermod -aG production dbuser1
usermod -aG operators consultant1
```

Create some files on the *NFS server* and set the appropriate permissions:

```
# Section 2 Lab Files
mkdir -p /shares/public
chgrp admin /shares/public
chmod g+sw /shares/public
echo "This is a sample file" > /shares/public/Delivered.txt
echo "This is a sample file" > /shares/public/NOTES.txt
echo "This is a sample file" > /shares/public/README.txt
echo "This is a sample file" > /shares/public/Trackings.txt

# Section 4 Lab Files
mkdir -p /shares/indirect/{west,central,east}
mkdir -p /shares/direct/external
chgrp -R operators /shares/indirect
chgrp -R contractors /shares/direct/external
chmod g+sw,o-rwx -R /shares/indirect
chmod g+sw,o-rwx -R /shares/direct
echo "This is a readme file" > /shares/indirect/west/README.txt
echo "This is a readme file" > /shares/indirect/central/README.txt
echo "This is a readme file" > /shares/indirect/east/README.txt
echo "This is a readme file" > /shares/direct/external/README.txt

# Section 5 Lab Files
mkdir -p /shares/{management,production,operation}
chgrp -R managers /shares/management
chgrp -R production /shares/production
chgrp -R operators /shares/operation
chmod g+sw,o-rwx -R /shares/management
chmod g+sw,o-rwx -R /shares/production
chmod g+sw,o-rwx -R /shares/operation
echo "This is a sample file" > /shares/management/Welcome.txt
echo "This is a sample file" > /shares/operation/Welcome.txt
echo "This is a sample file" > /shares/production/Welcome.txt
```

Create the NFS export files on the NFS server:

```
echo "/shares/public *(rw,no_root_squash)" > /etc/exports.d/public.exports
echo "/shares/direct *(rw,no_root_squash)" > /etc/exports.d/direct.exports
echo "/shares/indirect *(rw,no_root_squash)" > /etc/exports.d/indirect.exports
echo "/shares/management *(rw,no_root_squash)" > /etc/exports.d/remote.exports
echo "/shares/production *(rw,no_root_squash)" >> /etc/exports.d/remote.exports
echo "/shares/operation *(rw,no_root_squash)" >> /etc/exports.d/remote.exports
```

On the NFS server:  
`exportfs -ra` - Update the NFS configuration with the new exports  
`exportfs -v` - Verify the configuration.  You should see the new directories listed

Install `nfs-utils` on the client if necessary.

## Chapter 10 - Controlling the Boot Process

Commands to know:

* `systemctl poweroff` - Stops running processes and powers off system
* `systemctl reboot` - Stops running processes and reboots
* `systemctl list-units --type=target --all` - List all available targets
* `systemctl cat <target>` - Display target configuration file
* `systemctl isolate <target>` - Switches to different target.  Needs to have `AllowIsolate=yes` in config
* `systemctl get-default` - Shows default target
* `systemctl set-default <target>` - Sets default target
* `system.unit=<target>` - Set on `linux` kernel command line to set on a single boot

`systemd` common targets:

| Target | Purpose |
| ---    | --- |
| `graphical.target` | Multiple users, graphical and text-based logins |
| `mult-user.target` | Multiple users, text-based logins only          |
| `rescue.target`    | `sulogin` prompt, basic system initialization   |
| `emergency.target` | System root mounted on `/` as read only         |

To access `root` shell at boot (to reset a lost `root` password):

1. Interrupt boot process, append `rd.break` parameter to the `linux` kernal command line
1. `mount -o remount,rw /sysroot` - Remount `/sysroot` as in `rw` mode
1. `chroot /sysroot` - Make `/sysroot` the root directory
1. `passwd root` - Set a new root password
1. `touch /.autorelabel` - Make sure all unlabeled files get relabeled at boot, needed for changes made to `/etc/shadow`
1. `exit` - Twice, system will continue boot.  May take some time as SELinux relabels files

System journal logs are not persistent by default.  Set `Storage=persistent` in `/etc/systemd/journald.conf` so logs are saved to `/var/log/journal`.  
Use `journalctl -b -1 -p err` to show previous boot errors.

`systemctl list-jobs` inspects current job list.

File system errors during boot are often the result of errors in `/etc/fstab`.  Remember to run `systemctl daemon-reload` after editing `fstab` in emergency or rescue mode.

### Labs
Labs can be run as documented.

For the section 6 and 7 labs you will need to place an error in `fstab` and reboot:

```
echo "/dev/sdz1 /RemoveMe xfs defaults 0 0" >> /etc/fstab
```

## Chapter 11 - Managing Network Security

Commands to know:

* `man 5 firewalld.zones` - Default list of firewalld zones

`firewall-cmd` commands:

* `--get-services` - List of defined services
* `--get-default-zone` - List default zone
* `--get-zones` - List all available zones
* `--get-active-zones` - List zones currently in use
* `--set-default-zone=<zone>` - Sets the default zone
* `--list-all [--zone=<zone>]` - Lists configuration for zone (or default if not specified)
* `--list-all-zones` - List configurations for all zones
* `--add-service=<service> [--zone=<zone>]` - Allow traffic for service.  Also `--remove-service` to remove.  `--permanent` to save to permanent configuration
* `--add-port=<port/protocol> [--zone=<zone>]` - Allow traffice to port. Also `--remove-port` to remove.  `--permanent` to save to permanent configuration
* `--add-source=<ip_address>` - Allow traffic from IP address or subnet
* `--add-interface=<interface>` - Associate interface with zone
* `--reload` - Applies persistent configuration

SELinux also manages ports:

* `semanage port -l` - Show current port labels.  Add `-C` to view local changes
* `semanage port -a -t <label> -p <tcp|udp> <portnumber>` - Label a port. `-d` removes label.  `-m` modifies label
* `dnf install selinux-policy-doc` - Install `man` pages.  `man -k _selinux` to see topics
* `sealert -a /var/log/audit/audit.log` - View alerts

### Labs
You will want to use at least two systems in order to test the firewall configuration.

The section 4 lab creates an HTTP server which uses a non-standard port:

1. `dnf install httpd` - Install http server
1. `sed -i 's/Listen 80/Listen 82/g' /etc/httpd/conf/httpd.conf` - Change to port 82
1. `systemctl enable --now httpd` - Enable and try starting http service

The section 5 lab also creates an HTTP server with a non-standard port:

1. `sed -i 's/Listen 82/Listen 80/g' /etc/httpd/conf/httpd.conf` - Change back to port 80
1. `mkdir /var/www/html2` - Create the directory for the virtual server
1. `echo "VHOST 1" > /var/www/html2/index.html` - Create message to display 
1. Create `/etc/httpd/conf.d/vhost.conf` with the following:

   ```
   Listen 1001
   <VirtualHost your.ip.address:1001>
       ServerName serverb.lab.example.com
       DocumentRoot "/var/www/html2"
      <Directory "/var/www/html2">
         Require all granted
      </Directory>
   </VirtualHost>
   ```

   Replace `your.ip.address` with the IP address of the server you are using.  You may also want to update `ServerName` to match the hostname on that server.

1. `systemctl disable httpd` - Disable the httpd service
1. `systemctl stop httpd` - Make sure the httpd service is stopped
1. `firewall-cmd --add-service=http --permanent` - Enable the standard http port
1. `firewall-cmd --reload`

## Chapter 12 - Installing Red Hat Enterprise Linux
During installation Anaconda has multiple terminal sessions.  Use `Ctrl+Alt+F1` or `Ctrl+Alt+F6` to switch between them.  When in the `tmux` screen, use `Crtl+b #` to switch to another tmux window.

After a manual installation of RHEL/CentOS, a kickstart file is located in `/root/anaconda-ks.cfg`.

The [Kickstart generator website](https://access.redhat.com/labs/kickstartconfig/) may also be used to generate a kickstart file.

Pass kickstart file location using the `inst.ks=<location>` parameter on the install kernal command line.  Access the command line by pressing `Tab` at the first screen.

* `inst.ks=http://<server>/file`
* `inst.ks=ftp://...`
* `inst.ks=nfs:<server>:file`
* `inst.ks=hd:<device>:file`
* `inst.ks=cdrom:<device>`

Virtualization support:

* `dnf module install virt` - Installs KVM and associated packages
* `dnf install cockpit-machines` - Install Cockpit add-on for KVM

### Labs
For the labs, locate the ISO for CentOS or RHEL and configure a virtual machine to boot that image.

When editing the kickstart file, your file will probably not resemble the one used in the lab.

**NOTE** : As of VirtualBox v6.1.4, KVM will not run on a Linux guest inside VirtualBox.

## Chapter 13 - Comprehensive Review
