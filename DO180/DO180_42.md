# DO180 4.2 - Introduction to Containers, Kubernetes, and Red Hat OpenShift
Several of the labs can be run from a local install of RHEL or CentOS.  This not only 
saves online lab time but allows greater flexibility in experimenting and getting
hands-on experience.

These instructions assume you have a base RHEL or CentOS system installed.  I
recommend using [VirtualBox](https://www.virtualbox.org/) to install 
an OS which can be saved or deleted as needed.

Be sure to create a shared folder with your VM so you can copy files between the
host and the VM.

## Table of contents

[Chapter 2. Creating Containerized Services](#chapter-2-creating-containerized-services)  
[Chapter 3. Managing Containers](#chapter-3-managing-containers)  
[Chapter 4. Managing Container Images](#chapter-4-managing-container-images)  
[Chapter 5. Creating Custom Container Images](#chapter-5-creating-custom-container-images)  
[Chapter 6. Deploying Containerized Applications on OpenShift]()  
[]()  
[]()  
[]()  

## Windows Users
Here are a few items which may be of interest if you're using Windows as the host OS:
* The documentation lists long command using `\` as the line continuation character.
The line continuation character for Windows is the carat `^`

## Chapter 2. Creating Containerized Services
Commands to know:

* `podman search <text>` - search repositories for `text`
* `podman pull <image>` - pulls image.  Can be specified as `<registry_name>/<user_name>/<image_name>:tag`
* `podman images` - list local images


* `podman run --name <name> -e <env_var>=<env_value> -d <image>:<tags> -p <fwdport>:<containerport>` - runs an image.  `-d` starts container in the background. `-t` allocates a terminal.  `-i` for interactive
* `podman images`
* `podman exec -it <container> /bin/bash`

To delete all containers and images:
```
podman stop -a
podman rm -a
podman rmi -a
```
Use `podman rmi -f <image>` to force delete.

### Labs
Chapter 2 is an introduction to containers using [podman](https://podman.io/).  Installation
of podman is simple:
```
sudo yum -y install podman
```
Check the status with:
```
podman info
```
The rest of chapter 2 should work as documented.  The container being pulled will come from 
one of the default repositories.  

## Chapter 3. Managing Containers
Commands to know:

* `podman ps`- Displays actively running containers. `-a` includes stopped containers
* `podman run --name <name> -e <env_var>=<env_value> -d <image>:<tags> -p <fwdport>:<containerport>` - runs an image.  `-d` starts container in the background. `-t` allocates a terminal.  `-i` for interactive
* `podman run <image> <command>` - Runs `command` instead of default entry point when container is started
* `podman run -it rhscl/httpd-24-rhel7 /bin/bash` - Runs interactively and starts a shell
* `podman exec <container_id_or_name> <command>` - Runs `command` on already running container.  Use `-l` for last container instead of container name or ID

* `podman inspect <container>` - List container metadata
* `podman inspect -f '{{ .NetworkSettings.IPAddress }}' <container>` - View formatted output
* `podman stop <container>` - Stops running container gracefully
* `podman kill <container>` - Sends SIGKILL.  Use `-s SIGNAL` to send other signals.  See `man 7 signal` for list of all signals
* `podman restart <container>` - Restarts a stopped container.  Creates new container with same container ID, reuses state and filesystem from stopped container
* `podman rm <container>` - Deletes container

To mount a shared volume:
```
# Create directory and assign SELinux security context
mkdir <host_dir>
chown user:group <dir>
semanage fcontext -a -t container_file_t '<dir>(/.*)?'
restorecon -Rv <dir>

podman run -v <host_dir>:<container_mount> <container>
```

Port forwarding:

* `podman run -p <host_port>:<container_port> ...` - To create an externally available container
* `podman port <container>` - See port configuration

### Labs
This chapter continues the use of podman installed in the previous chapter.  In this chapter
we add a local installation of mysql:
```
yum install -y mysql
```
You may notice MariaDB gets installed.  This provides the `mysql` command used in this chapter.

All commands
should run as documented except in the case where the mysql script is called.  This command
will have to be executed manually.

In the *ch03s03* lab you may need to specify `-it` on the `podman exec mysql ...` command in step 10.

In the *ch03s06* lab the `/home/student/DO180/labs/manage-networking/db.sql` file will not be available.  Create the input file with these SQL commands:

```
CREATE TABLE Item (id int(11) NOT NULL AUTO_INCREMENT, description varchar(255) DEFAULT NULL, done bool DEFAULT 0, PRIMARY KEY (id));
insert into Item (id, description, done) values (1, 'Pick up newspaper', 0);
insert into Item (id, description, done) values (2, 'Buy groceries', 1);
```

## Chapter 4. Managing Container Images
Commands to know:
* `podman search <term>` - Finds images by name, username, or description
* `curl -Ls https://myserver/v2/_catalog` - use REST API to get list of repositories on registry server
* `podman login -u <user> -p <password> <registry>` - log in to a registry requiring authorization access
* `podman pull <registry:port>/name:tag` - specifies specific registry to pull image from

* `podman images` - lists local images
* `podman save -o <file_name> <image_name>:<tag>` - saves local image to `.tar` file
* `podman load -i <file_name>` - loads a saved image
* `podman rmi <image>` - deletes a local image.  `-a` deletes all images

Not recommended, but a running image can be saved in-place and saved.  `Dockerfile` is better approach.
* `podman commit <container> <image>` - Saves container to image
* `podman diff <container>` - identifies changes
* `podman tag <image> <new_image_tag>` - tags an image.  `latest` is assumed for tag unless tag is supplied
* `podman rmi <new_image_tag>` - Removes a tag
* `podman push <image>` - publishes image to registry

### Labs
Quay.io may not be listed in the default repositories.  Add it to the `registries.search` section in `/etc/containers/registries.conf`.

## Chapter 5. Creating Custom Container Images
Build an image from a `Dockerfile`:
1. Put all files in a working directory
1. Create the `Dockerfile`
1. `podman build -t <name>:<tag> <directory>`

`Dockerfile`:
* `# Comment` - comments
* `\` - line continuation 
* `FROM <base_image>` - Must be first non-comment instruction (`ARG` may also appear before)
* `LABEL <key>=<value>` - Adds metadata as key/value pair.  May have multiple pairs in single statement
* `MAINTAINER name <email>` - Author field
* `RUN <command>` - executes command using `/bin/sh` in new layer. Use `&&` to combine multiple commands in a single `RUN` statement
* `EXPOSE <port>` - container listens on port at runtime
* `ENV <name>=<value>` - creates environment variables.  May have multiple pairs in single statement
* `ADD <source> <dest>` - copy files/directories from local/remote source to destination in image.  Local files should be in working directory.  `.tar` files will be unpacked
* `COPY <source> <dest>` - copy files from working directory to image (no remote file support, does not decompress `tar` files)
* `USER <userid>` - specifies user ID or UID to use when running `RUN`, `CMD` and `ENTRYPOINT` instructions
* `ENTRYPOINT ["command"]` - default command to run when image runs in a container.  Default is `/bin/sh -c`
* `CMD [list_of_parameters]` - provides default arguments to `ENTRYPOINT`

`ENTRYPOINT` and `CMD` have two formats:
* Exec form uses JSON array (preferred): `ENTRYPOINT ["command", "arg1", "arg2"]`
* Shell form: `ENTRYPOINT command arg1 arg2`

`ADD` and `COPY` also have Exec and Shell forms.

### Labs
We can continue using our installed podman for most of these instructions.  

In the final lab you edit a Dockerfile template.  You can use the file created in the earlier lab as a template, although some of the commands will be missing.

## Chapter 6. Deploying Containerized Applications on OpenShift

Kubernetes resource types:
* *Pods* (po) - Collection of containers that share resources. Basic unit of work in Kubernetes
* *Services* (svc) - Single IP/port combo which provides access to a pool of pods
* *Replication controllers* (rc) - defines how pods are replicated into different nodes.  Provies HA.
* *Persistent volumes* (pv) - Storage areas used by pods
* *Persistent volume claims* (pvc) - Request for storage from a pod. PVC links PV to pod, mounted on pod file system
* *ConfigMaps* (cm) and *Secrets* - Key/values used by resources. Centralizes configuration.  Secrets are encoded

OpenShift adds:
* *Deployment config* (dc) - Set of containers included in pod and deployment strategies.
* *Build config* (bc) - Process to be executed in OpenShift project
* *Routes* - DNS hostname used as ingress point for apps and microservices

`oc` commands:
* `oc new-app` - Creates a new application.  This creates a Deployment Configuration, an Application (image stream), and the service
* `oc get <resource_type>` - Retrieve information about resource.  Use `all` for summary
* `oc describe <type> <name>` - Retrieve additional information about resource
* `oc export` - Export a resource definition
* `oc create` - Create resource from definition
* `oc edit` - Edit a resource definition
* `oc delete <type> <name>` - Deletes a resource
* `oc exec <container_id> <options> <command>` - Executes command in container
* `oc status` - Check status of application

Port-forwarding:  
`oc port-forward <pod_name> <local_port>:<remote(pod)_port>`  
Mapping only valid on the workstations where `oc port-forward` is running.  The terminal window must remain running.  `Ctrl+C` will stop the command.

Route:  
A route connects a public-facing ip address/DNS host name to an internal facing service IP.  Router pods bind to the public facing IP address.  Create using `oc create` and a definition file or using the `oc expose` command:  
`oc expose service <service> --name <name>`  
An external DNS name is generated for the route in the form `<route-name>-<project-name>.<default_domain>`.

* `oc get is -n openshift` - list default image streams
* `oc new-app <image_stream>~<git_url> --name=<name>` - Build app using S2I process

### Labs
You may use Red Hat ContainerReady Containers (CRC) for many of the OpenShift labs.  This allows you to install a minimal, single-node system for development and testing.  For details on installing CRC refer to the [Red Hat CodeReady Containers](https://developers.redhat.com/products/codeready-containers/overview) page.

Once CRC has been installed, the user ID and passwords for the developer and admin are displayed when CRC has been started:
```
INFO To access the cluster, first set up your environment by following 'crc oc-env' instructions 
INFO Then you can access it by running 'oc login -u developer -p developer https://api.crc.testing:6443' 
INFO To login as an admin, run 'oc login -u kubeadmin -p xxx-xxx-xxx https://api.crc.testing:6443' 
```
Use the `oc login` command provided by the `crc start` command to log into your CRC system.  You can also get credentials with: `crc console --credentials`.

The "Creating a Containerized Application with Source-to-Image" lab uses an application called `s2i-php-container`.  You can get [this application from Github](https://github.com/sclorg/s2i-php-container).

## Chapter 7
Chapter 7 uses more custom code than the previous chapters so may be somewhat more
difficult to replicate exactly in a home environment.

Remember - when using podman we had configured a VM with Linux and podman, but for
OpenShift we were using CDK/Minishift where the `oc` command is run from the host OS
(Windows in my case). 

### Section 7.2 Lab
Custom code used in this lab is located in the online environment in the `/home/student/DO180` 
directory after initializing the lab.  The relavent files for this particular chapter are
located in `multicontainer-design`.

To prepare, download all the files in the `ch7/multicontainer-design` directory and place
them in a directory on the VM we created earlier for podman. 

#### Step 1 - Mysql
In step 1 a custom Mysql image is built using podman.  The Dockerfile is provided as part of
the lab creates a base mysql image and copies some script files:

Dockerfile:
```
FROM rhscl/mysql-57-rhel7
ADD root /
```
If you're using CentOS you may need to modify this:
```
FROM centos/mysql-57-centos7
```
There are some files in the `root` directory which are Mysql initialization scripts.

#### Step 2 - Nodejs Parent
There are a number of changes we'll need to make in order to get this step working
in our environment.  
* If your system isn't registered and you're using CentOS, change `FROM rhel7:7.5` to
`FROM centos:centos7.5.1804`
* Do not include the `ADD training.repo ...` command since we're not in the lab environment
* Do not include the `RUN yum downgrade...` command
* The `RUN yum install...` command will need to be updated in order to find the 
package necessary.  Add `yum install -y centos-release-scl-rh && \` as the first command
to run in that set.  Also, remove any references to repositories in the remaining commands
* The `enable-rh-nodejs4.sh` file is used to automatically start Nodejs.  You can find a
copy of that file [in this blog entry](https://www.server-world.info/en/note?os=CentOS_7&p=nodejs4)
(see step 3).  They use a name of `rh-nodejs4.sh`, so whichever name you choose be sure to 
use the correct one in the Dockerfile

#### Steps 3-5 - To Do List Application
The To Do List application uses the Nodejs image created in Step 2 for a base.  You will
need to make a few changes to the lab files:
* Remove references to the repository in the `Dockerfile`:
```
RUN scl enable rh-nodejs4 'npm install'
```
* If you're using CentOS be sure to update the `networked/run.sh` command to point to the
correct image name.  Ie:
```
sudo podman run -d --name mysql -e MYSQL_DATABASE=items -e MYSQL_USER=user1 \
-e MYSQL_PASSWORD=mypa55 -e MYSQL_ROOT_PASSWORD=r00tpa55 \
-v $PWD/work/data:/var/lib/mysql/data \
-v $PWD/work/init:/var/lib/mysql/init -p 30306:3306 \
--ip 10.88.100.101 do180/mysql-57-centos7
```

### Section 7.4 Lab
This section uses some of the same files as the previous lab but adds OpenShift to
the configuration.  You'll also need your registry server up (see Chapter 4).

## Step 1 - MySQL
Use the same image you created in the previous lab.  Be sure to use your local 
registry server URL and port when tagging the image.  Also, if using CentOS update the image
name in the commands.  For example:
```
sudo podman tag do180/mysql-57-centos7 registry.home.parrill.net:5000/do180/mysql-57-centos7
sudo podman push registry.home.parrill.net:5000/do180/mysql-57-centos7
```

## Step 2 - Nodejs Parent
Similarly to the previous step, build the same image you created in the previous lab.  
This one doesn't need to be pushed to your custom registry.

## Step 3 - To Do List Application
Once again, build the To Do List application the same way you did in the previous
lab.  Like in Step 1 you will want to tag and push the image to your local registry server:
```
sudo podman tag do180/todonodejs registry.home.parrill.net:5000/do180/todonodejs
sudo podman push registry.home.parrill.net:5000/do180/todonodejs
```

## Step 4 - Persistent Volume Claims
Be sure to start CDK/Minishift.  `oc` commands need to run from your local host
system.
```
oc login -u admin -p admin
```
We will be unable to run the `create-pv.sh` command so the commands will have to 
be done manually.  A description of creating PVCs in Minishift is 
[given in this blog entry](https://developers.redhat.com/blog/2017/04/05/adding-persistent-storage-to-minishift-cdk-3-in-minutes/).

```
minishift ssh
sudo -i
mkdir -p /tmp/openshift/work/data /tmp/openshift/work/init
```
Next, create the db.sql file manually using vi:
```
vi /tmp/openshift/work/init/db.sql
```
Once in vi, press `i` to go into INSERT mode then past in the following lines:
```
DROP TABLE IF EXISTS `Item`;
CREATE TABLE `Item` (`id` BIGINT not null auto_increment primary key, `description` VARCHAR(100), `done` BIT);
INSERT INTO `Item` (`id`,`description`,`done`) VALUES (1,'Pick up newspaper', 0);
INSERT INTO `Item` (`id`,`description`,`done`) VALUES (2,'Buy groceries', 1);
```
Press `Esc` to exit Insert mode, then type `:wq` to save the file.  Back at the command prompt
finish setting the security context:
```
semanage fcontext -a -t container_file_t '/tmp/openshift/work(/.*)?'
restorecon -R /tmp/openshift/work
chown -R 27:27  /tmp/openshift/work
exit
exit
```
You should now be back at the host OS command prompt.  Copy the PV.json and PV2.json files
to your `C:\minishift` (or whichever directory you are using to run minishift commands from).
Run the following commands to create the PVCs:
```
oc delete pv pv0001
oc create -f PV.json
oc delete pv pv0002
oc create -f PV2.json
```

## Step 5 
Run step 5.1 as documented.

For step 5.2 run the following command to set the security policy:
```
oc adm policy add-scc-to-user anyuid -z default
```

For step 5.3 copy the `todo-template.json` to your `C:\minishift` directory before 
executing the command.  Edit the `todo-template.json` file and update it as needed
to point to the correct image names.  Also, update the file for your local
registry URL.  Change this in two places.




