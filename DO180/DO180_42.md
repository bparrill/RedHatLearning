# DO180 4.2 - Introduction to Containers, Kubernetes, and Red Hat OpenShift
Several of the labs can be run from a local install of RHEL or CentOS.  This not only 
saves online lab time but allows greater flexibility in experimenting and getting
hands-on experience.

These instructions assume you have a base RHEL or CentOS system installed.  I
recommend using [VirtualBox](https://www.virtualbox.org/) to install 
an OS which can be saved or deleted as needed.

Be sure to create a shared folder with your VM so you can copy files between the
host and the VM.

## Table of contents

[Chapter 2. Creating Containerized Services](#chapter-2-creating-containerized-services)  
[Chapter 3. Managing Containers](#chapter-3-managing-containers)  
[Chapter 4. Managing Container Images](#chapter-4-managing-container-images)  
[Chapter 5. Creating Custom Container Images](#chapter-5-creating-custom-container-images)  
[Chapter 6. Deploying Containerized Applications on OpenShift](#chapter-6-deploying-containerized-applications-on-openshift)  
[Chapter 7. Deploying Multi-Container Applications](#chapter-7-deploying-multi-container-applications)  
[Chapter 8. Troubleshooting Containerized Applications](#chapter-8-troubleshooting-containerized-applications)  

## Windows Users
Here are a few items which may be of interest if you're using Windows as the host OS:
* The documentation lists long command using `\` as the line continuation character.
The line continuation character for Windows is the carat `^`

## Chapter 2. Creating Containerized Services
Commands to know:

* `podman search <text>` - search repositories for `text`
* `podman pull <image>` - pulls image.  Can be specified as `<registry_name>/<user_name>/<image_name>:tag`
* `podman images` - list local images


* `podman run --name <name> -e <env_var>=<env_value> -d <image>:<tags> -p <fwdport>:<containerport>` - runs an image.  `-d` starts container in the background. `-t` allocates a terminal.  `-i` for interactive
* `podman images`
* `podman exec -it <container> /bin/bash`

To delete all containers and images:
```
podman stop -a
podman rm -a
podman rmi -a
```
Use `podman rmi -f <image>` to force delete.

### Labs
Chapter 2 is an introduction to containers using [podman](https://podman.io/).  Installation
of podman is simple:
```
sudo yum -y install podman
```
Check the status with:
```
podman info
```
The rest of chapter 2 should work as documented.  The container being pulled will come from 
one of the default repositories.  

## Chapter 3. Managing Containers
Commands to know:

* `podman ps`- Displays actively running containers. `-a` includes stopped containers
* `podman run --name <name> -e <env_var>=<env_value> -d <image>:<tags> -p <fwdport>:<containerport>` - runs an image.  `-d` starts container in the background. `-t` allocates a terminal.  `-i` for interactive
* `podman run <image> <command>` - Runs `command` instead of default entry point when container is started
* `podman run -it rhscl/httpd-24-rhel7 /bin/bash` - Runs interactively and starts a shell
* `podman exec <container_id_or_name> <command>` - Runs `command` on already running container.  Use `-l` for last container instead of container name or ID

* `podman inspect <container>` - List container metadata
* `podman inspect -f '{{ .NetworkSettings.IPAddress }}' <container>` - View formatted output
* `podman stop <container>` - Stops running container gracefully
* `podman kill <container>` - Sends SIGKILL.  Use `-s SIGNAL` to send other signals.  See `man 7 signal` for list of all signals
* `podman restart <container>` - Restarts a stopped container.  Creates new container with same container ID, reuses state and filesystem from stopped container
* `podman rm <container>` - Deletes container

To mount a shared volume:
```
# Create directory and assign SELinux security context
mkdir <host_dir>
chown user:group <dir>
semanage fcontext -a -t container_file_t '<dir>(/.*)?'
restorecon -Rv <dir>

podman run -v <host_dir>:<container_mount> <container>
```

Port forwarding:

* `podman run -p <host_port>:<container_port> ...` - To create an externally available container
* `podman port <container>` - See port configuration

### Labs
This chapter continues the use of podman installed in the previous chapter.  In this chapter
we add a local installation of mysql:
```
yum install -y mysql
```
You may notice MariaDB gets installed.  This provides the `mysql` command used in this chapter.

All commands
should run as documented except in the case where the mysql script is called.  This command
will have to be executed manually.

In the *ch03s03* lab you may need to specify `-it` on the `podman exec mysql ...` command in step 10.

In the *ch03s06* lab the `/home/student/DO180/labs/manage-networking/db.sql` file will not be available.  Create the input file with these SQL commands:

```
CREATE TABLE Item (id int(11) NOT NULL AUTO_INCREMENT, description varchar(255) DEFAULT NULL, done bool DEFAULT 0, PRIMARY KEY (id));
insert into Item (id, description, done) values (1, 'Pick up newspaper', 0);
insert into Item (id, description, done) values (2, 'Buy groceries', 1);
```

## Chapter 4. Managing Container Images
Commands to know:
* `podman search <term>` - Finds images by name, username, or description
* `curl -Ls https://myserver/v2/_catalog` - use REST API to get list of repositories on registry server
* `podman login -u <user> -p <password> <registry>` - log in to a registry requiring authorization access
* `podman pull <registry:port>/name:tag` - specifies specific registry to pull image from

* `podman images` - lists local images
* `podman save -o <file_name> <image_name>:<tag>` - saves local image to `.tar` file
* `podman load -i <file_name>` - loads a saved image
* `podman rmi <image>` - deletes a local image.  `-a` deletes all images

Not recommended, but a running image can be saved in-place and saved.  `Dockerfile` is better approach.
* `podman commit <container> <image>` - Saves container to image
* `podman diff <container>` - identifies changes
* `podman tag <image> <new_image_tag>` - tags an image.  `latest` is assumed for tag unless tag is supplied
* `podman rmi <new_image_tag>` - Removes a tag
* `podman push <image>` - publishes image to registry

### Labs
Quay.io may not be listed in the default repositories.  Add it to the `registries.search` section in `/etc/containers/registries.conf`.

## Chapter 5. Creating Custom Container Images
Build an image from a `Dockerfile`:
1. Put all files in a working directory
1. Create the `Dockerfile`
1. `podman build -t <name>:<tag> <directory>`

`Dockerfile`:
* `# Comment` - comments
* `\` - line continuation 
* `FROM <base_image>` - Must be first non-comment instruction (`ARG` may also appear before)
* `LABEL <key>=<value>` - Adds metadata as key/value pair.  May have multiple pairs in single statement
* `MAINTAINER name <email>` - Author field
* `RUN <command>` - executes command using `/bin/sh` in new layer. Use `&&` to combine multiple commands in a single `RUN` statement
* `EXPOSE <port>` - container listens on port at runtime
* `ENV <name>=<value>` - creates environment variables.  May have multiple pairs in single statement
* `ADD <source> <dest>` - copy files/directories from local/remote source to destination in image.  Local files should be in working directory.  `.tar` files will be unpacked
* `COPY <source> <dest>` - copy files from working directory to image (no remote file support, does not decompress `tar` files)
* `USER <userid>` - specifies user ID or UID to use when running `RUN`, `CMD` and `ENTRYPOINT` instructions
* `ENTRYPOINT ["command"]` - default command to run when image runs in a container.  Default is `/bin/sh -c`
* `CMD [list_of_parameters]` - provides default arguments to `ENTRYPOINT`

`ENTRYPOINT` and `CMD` have two formats:
* Exec form uses JSON array (preferred): `ENTRYPOINT ["command", "arg1", "arg2"]`
* Shell form: `ENTRYPOINT command arg1 arg2`

`ADD` and `COPY` also have Exec and Shell forms.

### Labs
We can continue using our installed podman for most of these instructions.  

In the final lab you edit a Dockerfile template.  You can use the file created in the earlier lab as a template, although some of the commands will be missing.

## Chapter 6. Deploying Containerized Applications on OpenShift

Kubernetes resource types:
* *Pods* (po) - Collection of containers that share resources. Basic unit of work in Kubernetes
* *Services* (svc) - Single IP/port combo which provides access to a pool of pods
* *Replication controllers* (rc) - defines how pods are replicated into different nodes.  Provies HA.
* *Persistent volumes* (pv) - Storage areas used by pods
* *Persistent volume claims* (pvc) - Request for storage from a pod. PVC links PV to pod, mounted on pod file system
* *ConfigMaps* (cm) and *Secrets* - Key/values used by resources. Centralizes configuration.  Secrets are encoded

OpenShift adds:
* *Deployment config* (dc) - Set of containers included in pod and deployment strategies.
* *Build config* (bc) - Process to be executed in OpenShift project
* *Routes* - DNS hostname used as ingress point for apps and microservices

`oc` commands:
* `oc new-app` - Creates a new application.  This creates a Deployment Configuration, an Application (image stream), and the service
* `oc get <resource_type>` - Retrieve information about resource.  Use `all` for summary
* `oc describe <type> <name>` - Retrieve additional information about resource
* `oc export` - Export a resource definition
* `oc create` - Create resource from definition
* `oc edit` - Edit a resource definition
* `oc delete <type> <name>` - Deletes a resource
* `oc exec <container_id> <options> <command>` - Executes command in container
* `oc status` - Check status of application

Port-forwarding:  
`oc port-forward <pod_name> <local_port>:<remote(pod)_port>`  
Mapping only valid on the workstations where `oc port-forward` is running.  The terminal window must remain running.  `Ctrl+C` will stop the command.

Route:  
A route connects a public-facing ip address/DNS host name to an internal facing service IP.  Router pods bind to the public facing IP address.  Create using `oc create` and a definition file or using the `oc expose` command:  
`oc expose service <service> --name <name>`  
An external DNS name is generated for the route in the form `<route-name>-<project-name>.<default_domain>`.

* `oc get is -n openshift` - list default image streams
* `oc new-app <image_stream>~<git_url> --name=<name>` - Build app using S2I process

### Labs
You may use Red Hat ContainerReady Containers (CRC) for many of the OpenShift labs.  This allows you to install a minimal, single-node system for development and testing.  For details on installing CRC refer to the [Red Hat CodeReady Containers](https://developers.redhat.com/products/codeready-containers/overview) page.

Once CRC has been installed, the user ID and passwords for the developer and admin are displayed when CRC has been started:
```
INFO To access the cluster, first set up your environment by following 'crc oc-env' instructions 
INFO Then you can access it by running 'oc login -u developer -p developer https://api.crc.testing:6443' 
INFO To login as an admin, run 'oc login -u kubeadmin -p xxx-xxx-xxx https://api.crc.testing:6443' 
```
Use the `oc login` command provided by the `crc start` command to log into your CRC system.  You can also get credentials with: `crc console --credentials`.

The "Creating a Containerized Application with Source-to-Image" lab uses an application called `s2i-php-container`.  You can get [this application from Github](https://github.com/sclorg/s2i-php-container).

## Chapter 7. Deploying Multi-Container Applications
Chapter 7 uses more custom code than the previous chapters so may be somewhat more
difficult to replicate exactly in a home environment.

Remember - when using podman we had configured a VM with Linux and podman, but for
OpenShift we were using CDK/Minishift where the `oc` command is run from the host OS
(Windows in my case). 

### Section 7.2 Lab
Custom code used in this lab is located in the online environment in the `/home/student/DO180` 
directory after initializing the lab.  The relavent files for this particular chapter are
located in `multicontainer-design`.

To prepare, download all the files in the `ch7/multicontainer-design` directory and place
them in a directory on the VM we created earlier for podman.

#### Step 1 - Mysql
In step 1 a custom Mysql image is built using podman.  The Dockerfile is provided as part of
the lab creates a base mysql image and copies some script files:

Dockerfile:
```
FROM rhscl/mysql-57-rhel7
ADD root /
```

There are some files in the `root` directory which are Mysql initialization scripts.  

#### Step 2 - Nodejs Parent
You'll need two files:

`Dockerfile`:
```
FROM    ubi7/ubi:7.7
MAINTAINER username <username@example.com>
ENV     NODEJS_VERSION=8.0 \
        HOME=/opt/app-root/src
RUN yum install -y --setopt=tsflags=nodocs rh-nodejs8 make && \
        yum clean all --noplugins -y && \
        mkdir -p /opt/app-root && \
        groupadd -r appuser -f -g 1001 && \
        useradd -u 1001 -r -g appuser -m -d ${HOME} -s /sbin/nologin \
            -c "Application User" appuser && \
        chown -R appuser:appuser /opt/app-root && \
        chmod -R 755 /opt/app-root
ADD     ./enable-rh-nodejs8.sh /etc/profile.d/
USER    appuser
WORKDIR ${HOME}
CMD     ["echo", "You must create your own container from this one."]
```

`enable-rh-nodejs8.sh`:
```
#!/bin/bash
source /opt/rh/rh-nodejs8/enable
export X_SCLS="`scl enable rh-nodejs8 'echo $X_SCLS'`"
```

#### Steps 3-5 - To Do List Application
The To Do List application uses the Nodejs image created in Step 2 for a base.  You will
need to make a few changes to the lab files:
* Remove references to the repository and the `ARG` statement in the `Dockerfile`
* Remove the references to the lab environment from `build.sh` and `run.sh`

### Section 7.4 Lab
This section uses some of the same files as the previous lab but adds OpenShift to
the configuration.  One change to be aware of, however, is the names of the images
in this lab are slightly different.  For example, when building the Mysql image
the name is `do180-mysql-57-rhel7` instead of `do180/mysql-57-rhel7` as used in
the previous lab.  You may want to edit the Nodejs deploy `Dockerfile` to point to
the correct image if you plan on using the new names.

## Chapter 8. Troubleshooting Containerized Applications
Commands to know:
* `oc logs bc/<app_name>` - Log for build configuration. `-f` to stream
* `oc start-build <app_name>` - Start a new build (after fixing app)
* `oc logs dc/<app_name>` - Log for deployment .  `-f` to stream

Permission issues:
* `oc adm policy add-scc-to-user anyuid -z default` - enables OCP executing container processes with non-root users
* `chown` - to fix file/folder permissions
* `semanage fcontext -a -t container_file_t <folder>` - required group for container volume

Invalid parameters:
* Use `ConfigMaps` to inject environment variables across multiple containers

Volume mount errors.  With PV on local file system, pod may fail allocating even if shown as released.  To fix, delete and recreate PV:
```
oc delete pv <pv_name>
oc create -f <pv_resource_file>
```

Images:
* `oc adm prune` - deletes obsolete images and other resources

Port forwarding is often used to temporarily access services in a container.  It's also good for remote debugging.
* `sudo podman run --name db -p <host_port>:<container_port> mysql` - maps host port to container port
* `oc port-forward db <host_port> <container_port>` - oc equivalent.  Only applies to host where command is running.  Only applies to single pod

Container logs & events:
* `podman logs <container>` - displays log of running container
* `oc logs <pod_name> [-c <container>]` - oc equivalent.  Container name is option if only one container in pod
* `oc get events` - Read OCP events (higher level than logs)
* `oc describe pod <pod_name>` - Has events section specific for pod

Access running containers:
* `sudo podman exec <container> <command> <arguments>` - runs a command in a container 
* `oc exec pod [-c container] -- <command> <arguments>` - OCP equivalent
* Example: `oc exec -it <podname> /bin/bash` - opens interactive command shell. `-i` pass stdin, `-t` creates terminal as stdin

Overriding binaries and copying files.  Useful to run commands which may not be in the container image:
* `sudo podman run -it -v /bin:/bin <image> /bin/bash` - starts a container and overrides image's `/bin` folder with the host's folder
* May also include needed utilities in base image using `RUN yum install ...` or equivalent
* `sudo podman cp <filename> <container>:<path_and_file>` - copies file to container
* `sudo podman cp <container>:<path_and_file> <filename>` - copies file from container
* `oc rsync` - OCP equivalent



### Labs
The ch08s02 lab should run as-is.  However, omit the `--build-env npm_config_registry=http://${RHT_OCP4_NEXUS_SERVER}/repository/npm-proxy` parameter from the `oc new-app` command in step 5.1.

The ch08s04 lab uses a custom Apache httpd image. 
1. The images is built from one which currently resides in `quay.io`.  Add `quay.io` to the `registries` entry in `/etc/containers/registries.conf`
1. Create a directory to hold your dockerfile: `mkdir -p troubleshoot-container/src`
1. Switch to the `troubleshoot-container` directory and create a `Dockerfile` with the following:
   ```
   FROM redhattraining/httpd-parent
   MAINTAINER me <me@example.com>
   RUN  sed -i 's/^ErrorLog .*/ErrorLog \/dev\/stdout/' /etc/httpd/conf/httpd.conf &&\
        sed -i 's/^LogLevel .*/LogLevel debug/' /etc/httpd/conf/httpd.conf &&\
        echo "CustomLog /dev/stdout common" >> /etc/httpd/conf/httpd.conf
   ```
   This creates the image and makes the necessary changes to the `httpd.conf` file



